{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0774d14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 3\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "file_docs = []\n",
    "\n",
    "with open ('cyb1.txt') as f:\n",
    "    tokens = sent_tokenize(f.read())\n",
    "    for line in tokens:\n",
    "        file_docs.append(line)\n",
    "        \n",
    "print(\"Number of documents:\", len(file_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce380e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_docs = [[w.lower() for w in word_tokenize(text)]\n",
    "            for text in file_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ee0218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'system',\n",
       "  'designed',\n",
       "  'to',\n",
       "  'prevent',\n",
       "  'unauthorized',\n",
       "  'access',\n",
       "  'to',\n",
       "  'or',\n",
       "  'from',\n",
       "  'a',\n",
       "  'private',\n",
       "  'network',\n",
       "  '.'],\n",
       " ['implemented',\n",
       "  'in',\n",
       "  'both',\n",
       "  'hardware',\n",
       "  'and',\n",
       "  'software',\n",
       "  'or',\n",
       "  'combination',\n",
       "  'of',\n",
       "  'both',\n",
       "  '.'],\n",
       " ['all',\n",
       "  'messages',\n",
       "  'entering',\n",
       "  'or',\n",
       "  'leaving',\n",
       "  'the',\n",
       "  'intranet',\n",
       "  'pass',\n",
       "  'through',\n",
       "  'the',\n",
       "  'firewall',\n",
       "  ',',\n",
       "  'which',\n",
       "  'examines',\n",
       "  'each',\n",
       "  'message',\n",
       "  'and',\n",
       "  'blocks',\n",
       "  'those',\n",
       "  'that',\n",
       "  'do',\n",
       "  'not',\n",
       "  'meet',\n",
       "  'the',\n",
       "  'specified',\n",
       "  'security',\n",
       "  'criteria',\n",
       "  '.']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bfbdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.': 0, 'a': 1, 'access': 2, 'designed': 3, 'from': 4, 'is': 5, 'it': 6, 'network': 7, 'or': 8, 'prevent': 9, 'private': 10, 'system': 11, 'to': 12, 'unauthorized': 13, 'and': 14, 'both': 15, 'combination': 16, 'hardware': 17, 'implemented': 18, 'in': 19, 'of': 20, 'software': 21, ',': 22, 'all': 23, 'blocks': 24, 'criteria': 25, 'do': 26, 'each': 27, 'entering': 28, 'examines': 29, 'firewall': 30, 'intranet': 31, 'leaving': 32, 'meet': 33, 'message': 34, 'messages': 35, 'not': 36, 'pass': 37, 'security': 38, 'specified': 39, 'that': 40, 'the': 41, 'those': 42, 'through': 43, 'which': 44}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e99445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86fa1d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1),\n",
       "  (1, 2),\n",
       "  (2, 1),\n",
       "  (3, 1),\n",
       "  (4, 1),\n",
       "  (5, 1),\n",
       "  (6, 1),\n",
       "  (7, 1),\n",
       "  (8, 1),\n",
       "  (9, 1),\n",
       "  (10, 1),\n",
       "  (11, 1),\n",
       "  (12, 2),\n",
       "  (13, 1)],\n",
       " [(0, 1),\n",
       "  (8, 1),\n",
       "  (14, 1),\n",
       "  (15, 2),\n",
       "  (16, 1),\n",
       "  (17, 1),\n",
       "  (18, 1),\n",
       "  (19, 1),\n",
       "  (20, 1),\n",
       "  (21, 1)],\n",
       " [(0, 1),\n",
       "  (8, 1),\n",
       "  (14, 1),\n",
       "  (22, 1),\n",
       "  (23, 1),\n",
       "  (24, 1),\n",
       "  (25, 1),\n",
       "  (26, 1),\n",
       "  (27, 1),\n",
       "  (28, 1),\n",
       "  (29, 1),\n",
       "  (30, 1),\n",
       "  (31, 1),\n",
       "  (32, 1),\n",
       "  (33, 1),\n",
       "  (34, 1),\n",
       "  (35, 1),\n",
       "  (36, 1),\n",
       "  (37, 1),\n",
       "  (38, 1),\n",
       "  (39, 1),\n",
       "  (40, 1),\n",
       "  (41, 3),\n",
       "  (42, 1),\n",
       "  (43, 1),\n",
       "  (44, 1)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "524a5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 0.47], ['access', 0.24], ['designed', 0.24], ['from', 0.24], ['is', 0.24], ['it', 0.24], ['network', 0.24], ['prevent', 0.24], ['private', 0.24], ['system', 0.24], ['to', 0.47], ['unauthorized', 0.24]]\n",
      "[['and', 0.12], ['both', 0.63], ['combination', 0.31], ['hardware', 0.31], ['implemented', 0.31], ['in', 0.31], ['of', 0.31], ['software', 0.31]]\n",
      "[['and', 0.07], [',', 0.18], ['all', 0.18], ['blocks', 0.18], ['criteria', 0.18], ['do', 0.18], ['each', 0.18], ['entering', 0.18], ['examines', 0.18], ['firewall', 0.18], ['intranet', 0.18], ['leaving', 0.18], ['meet', 0.18], ['message', 0.18], ['messages', 0.18], ['not', 0.18], ['pass', 0.18], ['security', 0.18], ['specified', 0.18], ['that', 0.18], ['the', 0.54], ['those', 0.18], ['through', 0.18], ['which', 0.18]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "for doc in tf_idf[corpus]:\n",
    "    print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dc4ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = gensim.similarities.Similarity('workdir/', tf_idf[corpus], num_features = len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aea04a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n"
     ]
    }
   ],
   "source": [
    "file2_docs = []\n",
    "\n",
    "with open('cyb2.txt') as f:\n",
    "    tokens = sent_tokenize(f.read())\n",
    "    \n",
    "    for line in tokens:\n",
    "        file2_docs.append(line)\n",
    "\n",
    "print(\"Number of documents:\", len(file2_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9177dff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in file2_docs:\n",
    "    query_doc = [w.lower() for w in word_tokenize(line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6224a5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'tool',\n",
       " 'that',\n",
       " 'isolates',\n",
       " 'our',\n",
       " 'computer',\n",
       " 'from',\n",
       " 'the',\n",
       " 'internet',\n",
       " 'using',\n",
       " 'a',\n",
       " 'wall',\n",
       " 'of',\n",
       " 'code',\n",
       " 'that',\n",
       " 'inspects',\n",
       " 'each',\n",
       " 'packet',\n",
       " 'of',\n",
       " 'data',\n",
       " 'entering',\n",
       " 'into',\n",
       " 'or',\n",
       " 'leaving',\n",
       " 'from',\n",
       " 'the',\n",
       " 'computer',\n",
       " 'and',\n",
       " 'prevents',\n",
       " 'any',\n",
       " 'type',\n",
       " 'of',\n",
       " 'attack',\n",
       " 'on',\n",
       " 'our',\n",
       " 'computer',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edf08818",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_doc_bow = dictionary.doc2bow(query_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e44abdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 2),\n",
       " (4, 2),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (8, 1),\n",
       " (14, 1),\n",
       " (20, 3),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (32, 1),\n",
       " (40, 2),\n",
       " (41, 2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_doc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c236da71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing results:  [0.34348628 0.17944168 0.36354676]\n"
     ]
    }
   ],
   "source": [
    "query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "\n",
    "print('Comparing results: ', sims[query_doc_tf_idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c6aee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8864747\n"
     ]
    }
   ],
   "source": [
    "sum_of_sims = (np.sum(sims[query_doc_tf_idf], dtype = np.float32))\n",
    "print(sum_of_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de1756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
